{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Classification Problem\nThis notebook will try to solve direction classification problem.\nThe Data phone sensors acceleration & gyroscope\nThe Target we will try to find the direction the phone moved - up, down, left, right, up left, up right, down left, down right "},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, LSTM, Dense, Dropout, LeakyReLU, Reshape, Bidirectional, LSTM, GlobalAveragePooling1D, GlobalMaxPooling1D\nfrom keras.layers import concatenate, Conv1D, BatchNormalization, Flatten, Multiply, Concatenate, Add, Subtract, Dot, Lambda, PReLU, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport tensorflow as tf","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nEPOCKS = 50","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"def load_data():\n    path = '../input/generations'\n    gens = None\n    paths = os.listdir(path)\n    for p in paths:\n        gen = pd.read_csv(path + '/' +p)\n        if gens is None:\n            gens = gen\n        else:\n            gens = pd.concat([gens, gen])\n    return gens\n\ngens = load_data()\ngens.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"   Unnamed: 0 tag  accelometer_x  accelometer_y  accelometer_z  gyroscope_x  \\\n0           0  up      -0.457306       3.747040       9.706390     0.001173   \n1           1  up      -0.629694       3.845205       9.775824    -0.000659   \n2           2  up       0.881093       2.636096       9.806950    -0.006768   \n3           3  up      -0.766168       2.188367       9.696813    -0.004324   \n4           4  up      -0.131685       1.106155       9.885961    -0.002492   \n\n   gyroscope_y  gyroscope_z  speed  \n0    -0.012273     0.005558    NaN  \n1    -0.004943     0.003725    NaN  \n2     0.013994     0.072753    NaN  \n3    -0.001888     0.292053    NaN  \n4    -0.002499     0.283501    NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>tag</th>\n      <th>accelometer_x</th>\n      <th>accelometer_y</th>\n      <th>accelometer_z</th>\n      <th>gyroscope_x</th>\n      <th>gyroscope_y</th>\n      <th>gyroscope_z</th>\n      <th>speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>up</td>\n      <td>-0.457306</td>\n      <td>3.747040</td>\n      <td>9.706390</td>\n      <td>0.001173</td>\n      <td>-0.012273</td>\n      <td>0.005558</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>up</td>\n      <td>-0.629694</td>\n      <td>3.845205</td>\n      <td>9.775824</td>\n      <td>-0.000659</td>\n      <td>-0.004943</td>\n      <td>0.003725</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>up</td>\n      <td>0.881093</td>\n      <td>2.636096</td>\n      <td>9.806950</td>\n      <td>-0.006768</td>\n      <td>0.013994</td>\n      <td>0.072753</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>up</td>\n      <td>-0.766168</td>\n      <td>2.188367</td>\n      <td>9.696813</td>\n      <td>-0.004324</td>\n      <td>-0.001888</td>\n      <td>0.292053</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>up</td>\n      <td>-0.131685</td>\n      <td>1.106155</td>\n      <td>9.885961</td>\n      <td>-0.002492</td>\n      <td>-0.002499</td>\n      <td>0.283501</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Analyzing The data & Split to train and test sets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def analyze_tags(gens):\n    tags = gens['tag'].unique()\n    print('tags (', len(tags) ,'): ', tags)\n    grouped = gens.groupby('tag').count()\n\nanalyze_tags(gens)","execution_count":6,"outputs":[{"output_type":"stream","text":"tags ( 8 ):  ['up' 'down' 'right' 'left' 'upright' 'downleft' 'upleft' 'downright']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_X_y(gens):\n    X = gens.drop(['tag','speed','Unnamed: 0'], axis=1)\n    y = gens['tag']\n    return X, y\n\nX, y = create_X_y(gens)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_train_test(X, y, precentage = 0.2):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=precentage)\n    print('X train shape: ',X_train.shape, ' y train shape: ', y_train.shape)\n    print('X test shape: ',X_test.shape, ' y test shape: ', y_test.shape)\n    return X_train, X_test, y_train, y_test\n\ndef y_to_categorical(y_train, y_test):\n    dic = {x:i for i,x in enumerate(y_train.unique())}\n    len_train = len(y_train)\n    y = np.concatenate([y_train.to_numpy(), y_test.to_numpy()])\n    y = [dic[x] for x in y]\n    y = to_categorical(y)\n    y_train = y[0:len_train]\n    y_test = [dic[x] for x in y_test]\n    print('Changed to catigorical','y train shape: ',len(y_train), ' y test shape: ', len(y_test))\n    return y_train, y_test, dic\n\nX_train, X_test, y_train, y_test = split_train_test(X, y)\ny_train, y_test, y_dic = y_to_categorical(y_train, y_test)","execution_count":8,"outputs":[{"output_type":"stream","text":"X train shape:  (4739, 6)  y train shape:  (4739,)\nX test shape:  (1185, 6)  y test shape:  (1185,)\nChanged to catigorical y train shape:  4739  y test shape:  1185\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_train_test_by_tag(gens, precentage = 0.2):\n    grouped = gens.groupby('tag')\n    X_train = None\n    X_test = None\n    y_train = None\n    y_test = None\n    for g in grouped:\n        X, y = create_X_y(g[1])\n        X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp = train_test_split(X, y)\n        if X_train is None:\n            X_train, X_test, y_train, y_test = X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp \n        else:\n            X_train = pd.concat([X_train, X_train_tmp])\n            y_train = pd.concat([y_train, y_train_tmp])\n            X_test = pd.concat([X_test, X_test_tmp])\n            y_test = pd.concat([y_test, y_test_tmp])\n    print('X grouped train shape: ',X_train.shape, ' y grouped train shape: ', y_train.shape)\n    print('X grouped test shape: ',X_test.shape, ' y grouped test shape: ', y_test.shape)\n    return X_train, X_test, y_train, y_test\n\n\nX_train_g, X_test_g, y_train_g, y_test_g = split_train_test_by_tag(gens)\ny_train_g, y_test_g, y_dic_g = y_to_categorical(y_train_g, y_test_g)","execution_count":9,"outputs":[{"output_type":"stream","text":"X grouped train shape:  (4441, 6)  y grouped train shape:  (4441,)\nX grouped test shape:  (1483, 6)  y grouped test shape:  (1483,)\nChanged to catigorical y train shape:  4441  y test shape:  1483\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_train_test_by_subtruction_close_points(X,y):\n    grouped = gens.groupby('tag')\n    X_tmp = None\n    y_tmp = None\n    X_original = None\n    for g in grouped:\n        X, y = create_X_y(g[1])\n        tmp_dic = {}\n        if X_original is None:\n            X_original = X.iloc[1:]\n        else:\n            X_original = pd.concat([X_original,X.iloc[1:]])\n        for col in X.columns:\n            tmp_dic['sub_'+col] = X[col].iloc[1:].values - X[col].iloc[:len(X)-1].values\n        if X_tmp is None:\n            X_tmp = pd.DataFrame.from_dict(tmp_dic)\n            y_tmp = y.iloc[:len(X)-1]\n        else:\n            X_tmp = pd.concat([X_tmp, pd.DataFrame.from_dict(tmp_dic)])\n            y_tmp = pd.concat([y_tmp, y.iloc[1:]])\n    X_original = X_original.reset_index()\n    X_tmp = X_tmp.reset_index()\n    X_tmp = pd.concat([X_tmp, X_original], axis=1)\n    X_tmp = X_tmp.drop(['index'], axis=1)\n    print('X subtract: ',X_tmp.shape, ' y substract: ', y_tmp.shape)\n    X_train, X_test, y_train, y_test = split_train_test(X_tmp, y_tmp)\n    return X_train, X_test, y_train, y_test\n\nX_train_s, X_test_s, y_train_s, y_test_s = split_train_test_by_subtruction_close_points(X, y)\ny_train_s, y_test_s, y_dic_s = y_to_categorical(y_train_s, y_test_s)","execution_count":10,"outputs":[{"output_type":"stream","text":"X subtract:  (5916, 12)  y substract:  (5916,)\nX train shape:  (4732, 12)  y train shape:  (4732,)\nX test shape:  (1184, 12)  y test shape:  (1184,)\nChanged to catigorical y train shape:  4732  y test shape:  1184\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_train_test_by_sliding_window(X,y, N=2):\n    grouped = gens.groupby('tag')\n    X_tmp = None\n    X_original = None\n    y_original = None\n    start = None\n    end = None\n    for g in grouped:\n        X, y = create_X_y(g[1])\n        start = N\n        end = len(X)\n        tmp_dic = {}\n        if X_original is None:\n            X_original = X.iloc[start-1:]\n            y_original = y.iloc[start-1:]\n        else:\n            X_original = pd.concat([X_original,X.iloc[start-1:]])\n            y_original = pd.concat([y_original, y.iloc[start-1:]])\n        for col in X.columns:\n            for i in range(N-1,0,-1):\n                name = 'prev_'+str(i)+'_'+col\n                tmp_dic[name] = X[col].iloc[start-i: end-i].values\n        if X_tmp is None:\n            X_tmp = pd.DataFrame.from_dict(tmp_dic)\n        else:\n            X_tmp = pd.concat([X_tmp, pd.DataFrame.from_dict(tmp_dic)])\n    X_original = X_original.reset_index()\n    X_tmp = X_tmp.reset_index()\n    X_tmp = pd.concat([X_tmp, X_original], axis=1)\n    X_tmp = X_tmp.drop(['index'], axis=1)\n    print('X subtract: ',X_tmp.shape, ' y substract: ', y_original.shape)\n    X_train, X_test, y_train, y_test = split_train_test(X_tmp, y_original)\n    return X_train, X_test, y_train, y_test\n\nX_train_d, X_test_d, y_train_d, y_test_d = split_train_test_by_sliding_window(X, y)\ny_train_d, y_test_d, y_dic_d = y_to_categorical(y_train_d, y_test_d)","execution_count":56,"outputs":[{"output_type":"stream","text":"X subtract:  (5916, 12)  y substract:  (5916,)\nX train shape:  (4732, 12)  y train shape:  (4732,)\nX test shape:  (1184, 12)  y test shape:  (1184,)\nChanged to catigorical y train shape:  4732  y test shape:  1184\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Creating Classification Naive Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_callbacks(name, patience=5):\n    early_stopping = EarlyStopping(patience=patience)\n    cheak_point = ModelCheckpoint(name)\n    return [early_stopping, cheak_point]\n\ndef create_metrics():\n    return ['accuracy']\n\ndef create_model1(size=6):\n    inp = Input(shape=(None,size))\n    x = Dense(32, activation='relu')(inp)\n    x = Dense(64, activation='relu')(x)\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=inp, outputs=x, name='model1') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel1 = create_model1()\ncallbacks = create_callbacks('model1.h5')\nhistory = model1.fit(X_train, y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.15, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## X,y not grouped "},{"metadata":{"trusted":true},"cell_type":"code","source":"def quick_plot_loss(history, field, metric, ax):\n    # Plot training & validation loss values\n    ax.plot(history.history[field])\n    ax.plot(history.history['val_'+field])\n    ax.set_title('Model '+ metric)\n    ax.set_ylabel(metric)\n    ax.set_xlabel('Epoch')\n    ax.legend(['Train', 'Validation'], loc='upper left')\n                \n    \ndef quick_plot_history(history):\n    fig = plt.figure(figsize=(18, 4))\n    ax = fig.add_subplot(1, 2, 1)\n    ax.set_title('loss')\n    quick_plot_loss(history, 'loss', 'categorical_crossentropy', ax)\n    ax = fig.add_subplot(1, 2, 2)\n    ax.set_title('accrucy')\n    quick_plot_loss(history, 'accuracy', 'accuracy', ax)\n    \nquick_plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_results(model,X_test,y_test, LOAD=True):\n    preds = model.predict(X_test)\n    pred_cat = np.argmax(preds,axis=1) #takes the maximum prediction and compare it to the real prediction\n    acc = accuracy_score(y_test,pred_cat)*100\n    acc_saved = -1\n    if LOAD:\n        saved_model = load_model('./'+model.name+'.h5')\n        preds = saved_model.predict(X_test)\n        pred_cat = np.argmax(preds,axis=1) #takes the maximum prediction and compare it to the real prediction\n        acc_saved = accuracy_score(y_test,pred_cat)*100\n    \n    if acc > acc_saved:\n        if LOAD:\n            model.save('./'+model.name+'.h5')\n        print('NEW: model accuracy on test set is: {0:.2f}%'.format(acc))\n    else:\n        print('model accuracy on test set is: {0:.2f}%'.format(acc_saved))\n\ntest_results(model1, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## X,y grouped "},{"metadata":{"trusted":true},"cell_type":"code","source":"model1_grouped = create_model1()\ncallbacks = create_callbacks('model1_grouped.h5')\nhistory = model1_grouped.fit(X_train_g, y_train_g, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's seems for the naive model The random split is much better then the group split, The group split made the model to be overfitting."},{"metadata":{},"cell_type":"markdown","source":"# Improvments - Building More complex models\n* model2 - added Droupout\n* model3 - added more nyrones to model 2\n* model4 - change the model architecture, added another dense moved the dropout to be the last, changed the first activation to tanh\n* model5 - change the model architecture to support LSTM, added Reshape\n* model6 - addeed more complexity model5"},{"metadata":{},"cell_type":"markdown","source":"# Model 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dense_block(inp, n=32):\n    x = Dense(n, activation='relu')(inp)\n    x = Dense(n*2, activation='relu')(x)\n    return x\n\ndef create_model2(size=6):\n    inp = Input(shape=(None,size))\n    x = dense_block(inp)\n    x = Dropout(0.2)(x)\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=inp, outputs=x, name='model2') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel2 = create_model2()\ncallbacks = create_callbacks('model2.h5')\nhistory = model2.fit(X_train, y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.15, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_results(model2, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems only adding a dropout improved the results on the test set from the naive model."},{"metadata":{},"cell_type":"markdown","source":"# Model 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model3(size=6):\n    inp = Input(shape=(None,size))\n    x = dense_block(inp, n=64)\n    x = Dropout(0.2)(x)\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=inp, outputs=x, name='model3') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel3 = create_model3()\ncallbacks = create_callbacks('model3.h5')\nhistory = model3.fit(X_train, y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.15, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_results(model3, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model4(size=6):\n    inp = Input(shape=(None,size))\n    x = Dense(16, activation='tanh')(inp)\n    x = Dense(32, activation='relu')(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=inp, outputs=x, name='model4') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel4 = create_model4()\ncallbacks = create_callbacks('model4.h5')\nhistory = model4.fit(X_train, y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_results(model4, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model5(size=6):\n    inp = Input(shape=(None,size))\n    x = Dense(256, activation='tanh')(inp)\n    x = Reshape([4,64])(x)\n    x = BatchNormalization(momentum=0.8)(x)\n    x = Bidirectional(LSTM(16))(x)\n    x = Flatten()(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=inp, outputs=x, name='model5') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel5 = create_model5()\ncallbacks = create_callbacks('model5.h5')\nhistory = model5.fit(X_train, y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_results(model5, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 6"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model6(size=6):\n    inp = Input(shape=(None,size))\n    x = Dense(1024, activation='tanh')(inp)\n    x = Reshape([16,64])(x)\n    x = BatchNormalization(momentum=0.5)(x)\n    x1 = Bidirectional(LSTM(64))(x)\n    x1 = Flatten()(x1)\n    x2 = GlobalAveragePooling1D()(x)\n    x3 = GlobalMaxPooling1D()(x)\n    x = concatenate([x1,x2,x3])\n    x = Dense(256, activation='relu')(x)\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=inp, outputs=x, name='model6') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel6 = create_model6()\ncallbacks = create_callbacks('model6.h5')\nhistory = model6.fit(X_train, y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_results(model6, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 7"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cov_blocks(inp, n, k):\n    x = Conv1D(n, kernel_size=k, padding='same', activation='relu')(inp)\n    x = Conv1D(n*2, kernel_size=k, padding='same', activation='relu')(x)\n    x = Conv1D(n*3, kernel_size=k, padding='same', activation='relu')(x)\n    x = Conv1D(n*4, kernel_size=k, padding='same', activation='relu')(x)\n    x = Conv1D(n*5, kernel_size=k, padding='same', activation='relu')(x)\n    x = Flatten()(x)\n    return x\n\ndef create_model7(size=6):\n    inp = Input(shape=(None,size))\n    x = Dense(256, activation='tanh')(inp)\n    x = Reshape([16,16])(x)\n    x1 = cov_blocks(x, 16, 3)\n    x2 = cov_blocks(x, 16, 4)\n    x3 = cov_blocks(x, 16, 5)\n    x = concatenate([x1,x2,x3])\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=inp, outputs=x, name='model7') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel7 = create_model7()\ncallbacks = create_callbacks('model7.h5')\nhistory = model7.fit(X_train, y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_results(model7, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## we will try creating a semaic model"},{"metadata":{},"cell_type":"markdown","source":"# Model 8"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Multiply, Concatenate, Add, Subtract\ndef seimaic(size=3):\n    inp = Input(shape=size)\n    x = Dense(16, activation='relu')(inp)\n    x = Dense(32, activation='relu')(x)\n    x = Dense(64, activation='relu')(x)\n    return inp, x\n\ndef create_model_seamic1():\n    inp1, s1 = seimaic()\n    inp2, s2 = seimaic()\n    x = concatenate([s1, s2])\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=[inp1, inp2], outputs=x, name='model8') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel8 = create_model_seamic1()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_semaic(X):\n    A = X.drop(['gyroscope_x','gyroscope_y','gyroscope_z'], axis=1)\n    B = X.drop(['accelometer_x','accelometer_y','accelometer_z'], axis=1)\n    return A, B\n\nA, B = split_semaic(X_train)\ncallbacks = create_callbacks('model8.h5')\nhistory = model8.fit([A,B], y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A, B = split_semaic(X_test)\ntest_results(model8, [A,B], y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 9"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dense_deapth_block(inp, N=32, extend_N=4, deapth=5):\n    if deapth==0:\n        return inp\n    x = None \n    prev_x = None\n    xs = []\n    for i in range(0, deapth):\n        if x is None:\n            x = Dense(N)(inp)\n            x = PReLU()(x)\n        else:\n            prev_x = x\n            x = Dense(N + i*extend_N)(prev_x)\n            x = PReLU()(x)\n        xs.append(x)\n    if len(xs) != 1:\n        x = concatenate(xs)\n    return x\n\ndef seimaic2(size=3, deapth=5):\n    inp = Input(shape=size)\n    x = dense_deapth_block(inp, deapth=deapth)\n    return inp, x\n\ndef create_model_seamic2():\n    inp1, s1 = seimaic2(deapth=2)\n    inp2, s2 = seimaic2()\n    x = concatenate([s1, s2])\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=[inp1, inp2], outputs=x, name='model9') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel9 = create_model_seamic2()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A, B = split_semaic(X_train)\ncallbacks = create_callbacks('model9.h5')\nhistory = model9.fit([A,B], y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A, B = split_semaic(X_test)\ntest_results(model9, [A,B], y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a Bench Mark"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nforest = RandomForestRegressor(n_estimators = 100, max_depth = 8)\nforest.fit(X_train,y_train)\ntest_results(forest, X_test, y_test, LOAD=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now that we pass the bench mark we will try to improve the model by extend the input model from 2 diffrent input chanels to 3,4,5 channels"},{"metadata":{},"cell_type":"markdown","source":"# Model 10"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_channels_3(X):\n    A = X.drop(['gyroscope_x','gyroscope_y','gyroscope_z'], axis=1)\n    B = X.drop(['accelometer_x','accelometer_y','accelometer_z'], axis=1)\n    C = X.copy()\n    return A, B, C\n\ndef create_chanel(size=3, deapth=5, N=32,extend_N=4):\n    inp = Input(shape=size)\n    x = dense_deapth_block(inp, deapth=deapth, N=N, extend_N=extend_N)\n    return inp, x\n\ndef create_model_channel_3():\n    inp1, c1 = create_chanel(deapth=2,N=64)\n    inp2, c2 = create_chanel(N=64)\n    inp3, c3 = create_chanel(size=6,deapth=2, N=12)\n    x = concatenate([c1, c2, c3])\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=[inp1, inp2, inp3], outputs=x, name='model10') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel10 = create_model_channel_3()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A, B, C = split_channels_3(X_train)\ncallbacks = create_callbacks('model10.h5')\nhistory = model10.fit([A,B,C], y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)\nA, B, C = split_channels_3(X_test)\ntest_results(model10, [A,B,C], y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 11"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_channels_4(X):\n    A = X.drop(['gyroscope_x','gyroscope_y','gyroscope_z'], axis=1)\n    B = X.drop(['accelometer_x','accelometer_y','accelometer_z'], axis=1)\n    C = X.drop(['gyroscope_y','gyroscope_z','accelometer_y','accelometer_z'], axis=1)\n    D = X.drop(['gyroscope_x','gyroscope_z','accelometer_x','accelometer_z'], axis=1)\n    return A, B, C, D\n\ndef create_model_channel_4():\n    inp1, c1 = create_chanel(deapth=2,N=64)\n    inp2, c2 = create_chanel(N=64)\n    inp3, c3 = create_chanel(size=2,deapth=2,N=12)\n    inp4, c4 = create_chanel(size=2,deapth=2,N=12)\n    x = concatenate([c1, c2, c3, c4])\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=[inp1, inp2, inp3, inp4], outputs=x, name='model11') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel11 = create_model_channel_4()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A, B, C, D = split_channels_4(X_train)\ncallbacks = create_callbacks('model11.h5')\nhistory = model11.fit([A, B, C, D], y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)\nA, B, C, D = split_channels_4(X_test)\n\ntest_results(model11, [A, B, C, D], y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 13"},{"metadata":{"trusted":true},"cell_type":"code","source":"def go_depper(inputs, deapth=1):\n    x = concatenate(inputs)\n    a ,N = x.shape \n    if deapth!=0:\n        x = dense_deapth_block(x, deapth=deapth, N=N)\n    x = Dense(8)(x)\n    return x\n    \ndef go_all_deper(inputs, group_size=2, deapth=2):\n    size = len(inputs)\n    xs = []\n    for i in range(size):\n        if size - i - group_size >= 0:\n            group = inputs[i:i+group_size]\n            x = go_depper(group, deapth=deapth)\n            xs.append(x)\n    if len(xs) == 1:\n        return xs[0]\n    x = concatenate(xs)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_channel_4_2():\n    inp1, c1 = create_chanel(deapth=2,N=32)\n    inp2, c2 = create_chanel(N=32)\n    inp3, c3 = create_chanel(size=2,deapth=2,N=6)\n    inp4, c4 = create_chanel(size=2,deapth=2,N=6)\n    \n    inp5 = concatenate([inp1,inp2])\n    c5 = dense_deapth_block(inp5,deapth=2,N=32)\n    \n    inp6 = concatenate([inp3,inp4])\n    c6 = dense_deapth_block(inp6,deapth=2,N=32)\n    \n    x = concatenate([c1,c2, c3, c4, c5, c6])\n    x = Dense(8)(x)\n    x = Activation('softmax')(x)\n    model = Model(inputs=[inp1, inp2, inp3, inp4], outputs=x, name='model13') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel13 = create_model_channel_4_2()\nmodel13.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A, B, C, D = split_channels_4(X_train)\ncallbacks = create_callbacks('model13.h5')\nhistory = model13.fit([A, B, C, D], y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)\nA, B, C, D = split_channels_4(X_test)\ntest_results(model13, [A, B, C, D], y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 12"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_channels_5(X):\n    A = X.drop(['gyroscope_x','gyroscope_y','gyroscope_z'], axis=1)\n    B = X.drop(['accelometer_x','accelometer_y','accelometer_z'], axis=1)\n    C = X.drop(['gyroscope_y','gyroscope_z','accelometer_y','accelometer_z'], axis=1)\n    D = X.drop(['gyroscope_x','gyroscope_z','accelometer_x','accelometer_z'], axis=1)\n    E = X.drop(['gyroscope_x','gyroscope_y','accelometer_x','accelometer_y'], axis=1)\n    return A, B, C, D, E\n\ndef create_model_channel_5():\n    inp1, c1 = create_chanel(deapth=2,N=32)\n    inp2, c2 = create_chanel(N=32)\n    inp3, c3 = create_chanel(size=2,deapth=2,N=8)\n    inp4, c4 = create_chanel(size=2,deapth=2,N=8)\n    inp5, c5 = create_chanel(size=2,deapth=2,N=8)\n    \n    \n    inp6= concatenate([inp1,inp2])\n    c6 = dense_deapth_block(inp6,deapth=2,N=32,extend_N=16)\n    \n    inp7 = concatenate([inp3,inp4])\n    c7 = dense_deapth_block(inp7,deapth=2,N=8)\n    \n    inp8 = concatenate([inp4,inp5])\n    c8 = dense_deapth_block(inp8,deapth=2,N=8)\n    \n    inp9 = concatenate([inp3,inp5])\n    c9 = dense_deapth_block(inp9,deapth=2,N=8)\n    \n    x = concatenate([c1,c2, c3, c4, c5, c6, c7, c8, c9])\n    x = Dense(100)(x)\n    x = PReLU()(x)\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=[inp1, inp2, inp3, inp4, inp5], outputs=x, name='model12') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel12 = create_model_channel_5()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A, B, C, D, E = split_channels_5(X_train)\ncallbacks = create_callbacks('model12.h5')\nhistory = model12.fit([A, B, C, D, E], y_train, epochs=200, batch_size=64, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)\nA, B, C, D, E = split_channels_5(X_test)\ntest_results(model12, [A, B, C, D, E], y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 14"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_channel_5_2():\n    inp1, c1 = create_chanel(deapth=2,N=32)\n    inp2, c2 = create_chanel(N=32)\n    inp3, c3 = create_chanel(size=2,deapth=2,N=8)\n    inp4, c4 = create_chanel(size=2,deapth=2,N=8)\n    inp5, c5 = create_chanel(size=2,deapth=2,N=8)\n    \n    inp7 = concatenate([inp3,inp4])\n    c7 = dense_deapth_block(inp7,deapth=2,N=8)\n    \n    inp8 = concatenate([inp4,inp5])\n    c8 = dense_deapth_block(inp8,deapth=2,N=8)\n    \n    inp9 = concatenate([inp3,inp5])\n    c9 = dense_deapth_block(inp9,deapth=2,N=8)\n    \n    x2 = concatenate([c1, c2, c3, c4, c5, c7, c8, c9])\n    x2 = Dense(8)(x2)\n    x2 = PReLU()(x2)\n    \n    x1 = concatenate([c1, c2, c3, c4, c5])\n    x1 = Dense(8)(x1)\n    x1 = PReLU()(x1)\n    \n    x0 = concatenate([c1, c2])\n    x0 = Dense(8)(x0)\n    x0 = PReLU()(x0)\n    \n    x = concatenate([x0,x1,x2])\n    x = Dense(8, activation='softmax')(x)\n    \n    model = Model(inputs=[inp1, inp2, inp3, inp4, inp5], outputs=x, name='model14') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel14 = create_model_channel_5_2()\nmodel14.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A, B, C, D, E = split_channels_5(X_train)\ncallbacks = create_callbacks('model14.h5')\nhistory = model14.fit([A, B, C, D, E], y_train, epochs=200, batch_size=64, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)\nA, B, C, D, E = split_channels_5(X_test)\ntest_results(model14, [A, B, C, D, E], y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 15"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train_d.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_channels_4_d(X):\n    A = X.drop(['gyroscope_x','gyroscope_y','gyroscope_z', \n                'sub_gyroscope_x','sub_gyroscope_y','sub_gyroscope_z', \n                'sub_accelometer_x','sub_accelometer_y','sub_accelometer_z'], axis=1)\n    B = X.drop(['accelometer_x','accelometer_y','accelometer_z',\n                'sub_gyroscope_x','sub_gyroscope_y','sub_gyroscope_z', \n                'sub_accelometer_x','sub_accelometer_y','sub_accelometer_z'], axis=1)\n    C = X.drop(['gyroscope_x','gyroscope_y','gyroscope_z', \n                'sub_gyroscope_x','sub_gyroscope_y','sub_gyroscope_z', \n                'accelometer_x','accelometer_y','accelometer_z'], axis=1)\n    D = X.drop(['gyroscope_x','gyroscope_y','gyroscope_z', \n                'accelometer_x','accelometer_y','accelometer_z', \n                'sub_accelometer_x','sub_accelometer_y','sub_accelometer_z'], axis=1)\n    return A, B, C, D\n\ndef create_model_channel_4_d():\n    inp1, c1 = create_chanel(deapth=2,N=32)\n    inp2, c2 = create_chanel(N=32)\n    inp3, c3 = create_chanel(N=32)\n    inp4, c4 = create_chanel(N=32)\n    x = concatenate([c1, c2, c3, c4])\n    x = Dense(8, activation='softmax')(x)\n    model = Model(inputs=[inp1, inp2, inp3, inp4], outputs=x, name='model15') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nmodel15 = create_model_channel_4_d()\nmodel15.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A, B, C, D = split_channels_4_d(X_train_d)\ncallbacks = create_callbacks('model15.h5')\nhistory = model15.fit([A, B, C, D], y_train_d, epochs=200, batch_size=64, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick_plot_history(history)\nA, B, C, D = split_channels_4_d(X_test_d)\ntest_results(model15, [A, B, C, D], y_test_d)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 16"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_d_3, X_test_d_3, y_train_d_3, y_test_d_3 = split_train_test_by_sliding_window(X, y, N=3)\ny_train_d_3, y_test_d_3, y_dic_d_3 = y_to_categorical(y_train_d_3, y_test_d_3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train_d_3.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regression Problem"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tag_to_vector(tag):\n    vx = 5\n    vy = 5\n    if tag == 'up': \n        return [0, vy]\n    elif tag == 'down':\n        return [0, -vy]\n    elif tag == 'right':\n        return [vx, 0]\n    elif tag == 'left':\n        return [-vx, 0]\n    elif tag == 'upright':\n        return [vx, vy]\n    elif tag == 'downleft':\n        return [-vx, -vy]\n    elif tag == 'upleft':\n        return [-vx, vy]\n    #elif tag =='downright'\n    return [vx, -vy]\n\ndef y_to_vector_speed(y_train, y_test):\n    y_train = [tag_to_vector(x) for x in y_train]\n    y_test = [tag_to_vector(x) for x in y_test]\n    y_train = y_train.to_numpy()\n    print('Changed to vector','y train shape: ',len(y_train), ' y test shape: ', len(y_test))\n    return y_train, y_test\n    \nX_train, X_test, y_train, y_test = split_train_test(X, y)\ny_train, y_test = y_to_vector_speed(y_train, y_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}